{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "38bfbd5ada16035c96bb21265c51de80361f17b4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7d34243045b8e681bf168dc908a9388a2ceb5fa3"
   },
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data' #cloud í™˜ê²½ìœ¼ë¡œ ê²½ë¡œ ë³€ê²½\n",
    "\n",
    "train_data_path = join(data_dir,'train.csv')\n",
    "sub_data_path = join(data_dir, 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f0d3320a32138c92ed7b0629a57bd5a719603b0"
   },
   "source": [
    "## 1. ë°ì´í„° ì‚´í´ë³´ê¸°\n",
    "pandasì˜ read_csv í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ê³ , ê° ë³€ìˆ˜ë“¤ì´ ë‚˜íƒ€ë‚´ëŠ” ì˜ë¯¸ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "1. ID : ì§‘ì„ êµ¬ë¶„í•˜ëŠ” ë²ˆí˜¸\n",
    "2. date : ì§‘ì„ êµ¬ë§¤í•œ ë‚ ì§œ\n",
    "3. price : íƒ€ê²Ÿ ë³€ìˆ˜ì¸ ì§‘ì˜ ê°€ê²©\n",
    "4. bedrooms : ì¹¨ì‹¤ì˜ ìˆ˜\n",
    "5. bathrooms : ì¹¨ì‹¤ë‹¹ í™”ì¥ì‹¤ ê°œìˆ˜\n",
    "6. sqft_living : ì£¼ê±° ê³µê°„ì˜ í‰ë°© í”¼íŠ¸\n",
    "7. sqft_lot : ë¶€ì§€ì˜ í‰ë°© í”¼íŠ¸\n",
    "8. floors : ì§‘ì˜ ì¸µ ìˆ˜\n",
    "9. waterfront : ì§‘ì˜ ì „ë°©ì— ê°•ì´ íë¥´ëŠ”ì§€ ìœ ë¬´ (a.k.a. ë¦¬ë²„ë·°)\n",
    "10. view : ì§‘ì´ ì–¼ë§ˆë‚˜ ì¢‹ì•„ ë³´ì´ëŠ”ì§€ì˜ ì •ë„\n",
    "11. condition : ì§‘ì˜ ì „ë°˜ì ì¸ ìƒíƒœ\n",
    "12. grade : King County grading ì‹œìŠ¤í…œ ê¸°ì¤€ìœ¼ë¡œ ë§¤ê¸´ ì§‘ì˜ ë“±ê¸‰\n",
    "13. sqft_above : ì§€í•˜ì‹¤ì„ ì œì™¸í•œ í‰ë°© í”¼íŠ¸\n",
    "14. sqft_basement : ì§€í•˜ì‹¤ì˜ í‰ë°© í”¼íŠ¸\n",
    "15. yr_built : ì§‘ì„ ì§€ì€ ë…„ë„\n",
    "16. yr_renovated : ì§‘ì„ ì¬ê±´ì¶•í•œ ë…„ë„\n",
    "17. zipcode : ìš°í¸ë²ˆí˜¸\n",
    "18. lat : ìœ„ë„\n",
    "19. long : ê²½ë„\n",
    "20. sqft_living15 : 2015ë…„ ê¸°ì¤€ ì£¼ê±° ê³µê°„ì˜ í‰ë°© í”¼íŠ¸(ì§‘ì„ ì¬ê±´ì¶•í–ˆë‹¤ë©´, ë³€í™”ê°€ ìˆì„ ìˆ˜ ìˆìŒ)\n",
    "21. sqft_lot15 : 2015ë…„ ê¸°ì¤€ ë¶€ì§€ì˜ í‰ë°© í”¼íŠ¸(ì§‘ì„ ì¬ê±´ì¶•í–ˆë‹¤ë©´, ë³€í™”ê°€ ìˆì„ ìˆ˜ ìˆìŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "df5891d33b4d5f08c0011b712f8796417564ec17"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aiffel/aiffel/kaggle_kakr_housing/data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-04f7721da341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train data dim : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sub data dim : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#price column x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m             )\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/aiffel/aiffel/kaggle_kakr_housing/data/train.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print('train data dim : {}'.format(data.shape))\n",
    "print('sub data dim : {}'.format(sub.shape)) #price column x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label column ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "251c25b4f9c89db8b6643448369198e94437cfd7"
   },
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "\n",
    "del data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° íƒìƒ‰ ìœ„í•´ì„œ í•©ì³ì„œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc5d87141207fedeb521461bd0d0cc23c0c594f2"
   },
   "outputs": [],
   "source": [
    "train_len = len(data) #ë‚˜ì¤‘ì— í•™ìŠµ ë°ì´í„°ë§Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡\n",
    "data = pd.concat((data, sub), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96537247c40a4932e581a5c681d73348f6b3936b"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39cc64c64be8d6f2ebd5c7c2523973bbcfb29c94"
   },
   "source": [
    "## 2. ê°„ë‹¨í•œ ì „ì²˜ë¦¬ \n",
    "ê° ë³€ìˆ˜ë“¤ì— ëŒ€í•´ ê²°ì¸¡ ìœ ë¬´ë¥¼ í™•ì¸í•˜ê³ , ë¶„í¬ë¥¼ í™•ì¸í•´ë³´ë©´ì„œ ê°„ë‹¨í•˜ê²Œ ì „ì²˜ë¦¬ë¥¼ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "### ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "ë¨¼ì € ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ”ì§€ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.<br>\n",
    "missingno ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ matrix í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´, ë°ì´í„°ì˜ ê²°ì¸¡ ìƒíƒœë¥¼ ì‹œê°í™”ë¥¼ í†µí•´ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e8ce87398995d2f86fc5cb7b15294f46ece7801"
   },
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ì¸¡ì¹˜ : í°ìƒ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a89a32c9e3491c45bf3188d22a40a211e3850d66"
   },
   "source": [
    "ëª¨ë“  ë³€ìˆ˜ì— ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥´ë‹ˆ í™•ì‹¤í•˜ê²Œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pd.isnull(data[c]),c] ==> data[c]ì—ì„œì˜ ê²°ì¸¡ê°’ í™•ì¸(ì „ì²´ series ì¶œë ¥). c columnë§Œ ì¶œë ¥ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isnull.sum()ë‘ ë‹¤ë¥¸ ì ??..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f406f14203d742ff26da3454935aa05c8364922",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[pd.isnull(data['view']),'long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94ad23d7a91a68c1be7fcd4953013f5353541545"
   },
   "source": [
    "### id, date ë³€ìˆ˜ ì •ë¦¬\n",
    "id ë³€ìˆ˜ëŠ” ëª¨ë¸ì´ ì§‘ê°’ì„ ì˜ˆì¸¡í•˜ëŠ”ë° ë„ì›€ì„ ì£¼ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°í•©ë‹ˆë‹¤.<br>\n",
    "date ë³€ìˆ˜ëŠ” ì—°ì›”ì¼ì‹œê°„ìœ¼ë¡œ ê°’ì„ ê°€ì§€ê³  ìˆëŠ”ë°, ì—°ì›”ë§Œ ê³ ë ¤í•˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ ë§Œë“¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c48e1c16ec0725128286a0d524faff9bd725ed4"
   },
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "data['date'] = data['date'].apply(lambda x : str(x[:6])).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "200283a8d82a4f8c1951013961b5af3f91cc8be1"
   },
   "source": [
    "### ê° ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ í™•ì¸\n",
    "í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬ëŠ” ëª¨ë¸ì´ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•˜ê¸°ì— ì¢‹ì§€ ì•Šì€ ì˜í–¥ì„ ë¯¸ì¹˜ë¯€ë¡œ ë‹¤ë“¬ì–´ì¤„ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2aa785314a8bb8d9f84bbc17cb55e38c564a8f3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))\n",
    "\n",
    "# id ë³€ìˆ˜ëŠ” ì œì™¸í•˜ê³  ë¶„í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count+=1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b377cd53ae25ab16f09d303c5cf0019bc004f465"
   },
   "source": [
    "price, bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement ë³€ìˆ˜ê°€ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ê²½í–¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.<br>\n",
    "log-scalingì„ í†µí•´ ë°ì´í„° ë¶„í¬ë¥¼ ì •ê·œë¶„í¬ì— ê°€ê¹ê²Œ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log í™” : ë„“ì€ ê²ƒì„ ì¢ê²Œ , ì¢ì€ ê²ƒì„ ë„“ê²Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24bb873fdfcdf1511b75aff69456b49d36f8f637"
   },
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "876da0a04810168164a97239fc809ea38b277cdb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "count = 0\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        if count == 5:\n",
    "            break\n",
    "        sns.kdeplot(data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5923d97d51ae10050473c02eb8d56afa6d3e7567"
   },
   "source": [
    "ì–´ëŠì •ë„ ì¹˜ìš°ì¹¨ì´ ì¤„ì–´ë“  ë¶„í¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4d31773ba934e8b48564fb8207df9e574b3a195"
   },
   "outputs": [],
   "source": [
    "sub = data.iloc[train_len:, :]\n",
    "x = data.iloc[:train_len, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4afe676edcf34f694c95c3f0e6287d13edaee26"
   },
   "source": [
    "## 3. ëª¨ë¸ë§\n",
    "### Average Blending\n",
    "ì—¬ëŸ¬ê°€ì§€ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì‚°ìˆ  í‰ê· ì„ í†µí•´ Blending ëª¨ë¸ì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "296645421a135dc34c45f822ce73d31eeb107bdc"
   },
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=2019)\n",
    "xgboost = xgb.XGBRegressor(random_state=2019)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=2019)\n",
    "\n",
    "models = [{'model':gboost, 'name':'GradientBoosting'}, {'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "578896883c6b8c6a2c5785a93121b62506b22a21"
   },
   "source": [
    "### Cross Validation\n",
    "êµì°¨ ê²€ì¦ì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°„ë‹¨íˆ í‰ê°€í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b48689d7989107ea3524126c330e2225a58e4d3"
   },
   "outputs": [],
   "source": [
    "def get_cv_score(models):\n",
    "    kfold = KFold(n_splits=5, random_state=2019).get_n_splits(x.values)\n",
    "    for m in models:\n",
    "        print(\"Model {} CV score : {:.4f}\".format(m['name'], np.mean(cross_val_score(m['model'], x.values, y)), \n",
    "                                             kf=kfold)) #kfì•ˆì“°ì´ëŠ”ê±´ê°€??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53ea586dd0b4fe5481db7bfb9cbcb998ef88b648"
   },
   "outputs": [],
   "source": [
    "get_cv_score(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a26c1d6aa9b779077f84ec60b7f29385fc2e058b"
   },
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1004d9b01d1c3068d9e8a81f263315435478e591"
   },
   "source": [
    "íšŒê·€ ëª¨ë¸ì˜ ê²½ìš°ì—ëŠ” cross_val_score í•¨ìˆ˜ê°€ R<sup>2</sup>ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.<br>\n",
    "R<sup>2</sup> ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì˜ í‘œí˜„í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 3ê°œ íŠ¸ë¦¬ ëª¨ë¸ì´ ìƒë‹¹íˆ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ ê´œì°®ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.<br> í›ˆë ¨ ë°ì´í„°ì…‹ìœ¼ë¡œ 3ê°œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³ , Average Blendingì„ í†µí•´ ì œì¶œ ê²°ê³¼ë¥¼ ë§Œë“¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20af2394b94bdc14fe1b23688874fadbf1c2846a"
   },
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y)\n",
    "    \n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models #forë¬¸ ë’¤ì— ì¨ë„ ë˜ëŠ”êµ¬ë‚˜.\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7bdb1c740291e6d1721cf02cd3f59bb79153c87"
   },
   "outputs": [],
   "source": [
    "y_pred = AveragingBlending(models, x, y, sub) #x , y : í›ˆë ¨ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission csvíŒŒì¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv íŒŒì¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c9d0901bcf5e4754b40a6922292c04951b81bae"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data={'id':sub_id,'price':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2047d6ee5f5da05e5463d51d1fbbe82a94732a48"
   },
   "outputs": [],
   "source": [
    "my_submission_path = join(data_dir, 'submission.csv')\n",
    "result.to_csv(my_submission_path, index=False)\n",
    "\n",
    "print(my_submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì§ì ‘ íŠœë‹í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv') \n",
    "\n",
    "train = pd.read_csv(train_data_path)\n",
    "test = pd.read_csv(test_data_path)\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataë¥¼ intí˜•ìœ¼ë¡œ ë°”ê¿” ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì„±ìœ¼ë¡œ ì‚¬ìš©í•˜ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['date'].apply(lambda i: i[:6]).astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target dataì¸ priceë¥¼ ë”°ë¡œ yë¡œ ë¹¼ì„œ ì €ì¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "del train['price']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì¸¡ì— ë„ì›€ë˜ì§€ ì•ŠëŠ” id column ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['id']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataì— ëŒ€í•´ì„œë„ ë˜‘ê°™ì´ ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date'] = test['date'].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "del test['id']\n",
    "\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y ë¶„í¬ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì™¼ìª½ìœ¼ë¡œ í¬ê²Œ ì¹˜ìš°ì³ì§„ í˜•íƒœ. np.log1p() í•¨ìˆ˜ í†µí•´ ì •ê·œí™”í›„ ë‚˜ì¤‘ì— predict ê²°ê³¼ë¥¼ np.exp1m()ì„ í†µí•´ ë˜ëŒë¦°ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŠœë‹ì„ ìœ„í•´ì„  ë°˜ë³µë˜ëŠ” ì‘ì—…ì„ í•¨ìˆ˜ë¡œ ë¬¶ëŠ” ê²ƒì´ í•„ìš”í•˜ë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logí™” ëœ ì˜ˆì¸¡ ê²°ê³¼ì´ë¯€ë¡œ RMSE ê³„ì‚° ì „ì— np.expm1ì„ í†µí•´ì„œ ë‹¤ì‹œ ë˜ëŒë¦°ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_stateëŠ” ëª¨ë¸ì´ˆê¸°í™”ë‚˜ ë°ì´í„°ì…‹ êµ¬ì„±ì— ì‚¬ìš©ë˜ëŠ” ëœë¤ ì‹œë“œê°’ì…ë‹ˆë‹¤. \n",
    "#random_state=None    # ì´ê²Œ ì´ˆê¸°ê°’ì…ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì§€ì •í•˜ì§€ ì•Šê³  Noneì„ ë„˜ê²¨ì£¼ë©´ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì„ì˜ë¡œ ì„ íƒí•©ë‹ˆë‹¤.  \n",
    "random_state=2020        # í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì´ë ‡ê²Œ ê³ ì •ê°’ì„ ì„¸íŒ…í•´ ë‘ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ì´ë¦„ ì–»ê¸° : ì´ë¥¼ í†µí•´ì„œ ëª¨ë¸ ëª… ì ‘ê·¼ ê°€ëŠ¥!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gboost.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "for model in models:\n",
    "    # ëª¨ë¸ ì´ë¦„ íšë“\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # train, test ë°ì´í„°ì…‹ ë¶„ë¦¬ - ì—¬ê¸°ì—ë„ random_stateë¥¼ ê³ ì •í•©ë‹ˆë‹¤. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ì˜ rmseê°’ ì €ì¥\n",
    "    df[model_name] = rmse(y_test, y_pred)\n",
    "    \n",
    "    # data frameì— ì €ì¥\n",
    "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•¨ìˆ˜í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train, y):\n",
    "    \n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "    # ëª¨ë¸ ì´ë¦„ íšë“\n",
    "    \tmodel_name = model.__class__.__name__\n",
    "\n",
    "    \t# train, test ë°ì´í„°ì…‹ ë¶„ë¦¬ - ì—¬ê¸°ì—ë„ random_stateë¥¼ ê³ ì •í•©ë‹ˆë‹¤. \n",
    "    \tX_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    \t# ëª¨ë¸ í•™ìŠµ\n",
    "    \tmodel.fit(X_train, y_train)\n",
    "    \n",
    "    \t# ì˜ˆì¸¡\n",
    "    \ty_pred = model.predict(X_test)\n",
    "\n",
    "    \t# ì˜ˆì¸¡ ê²°ê³¼ì˜ rmseê°’ ì €ì¥\n",
    "    \tdf[model_name] = rmse(y_test, y_pred)\n",
    "    \n",
    "    \t# data frameì— ì €ì¥\n",
    "    \tscore_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    return score_df\n",
    "\n",
    "get_scores(models, train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search ì´ìš©í•´ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCVì— ì…ë ¥ë˜ëŠ” ì¸ìë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- param_grid : íƒìƒ‰í•  íŒŒë¼ë¯¸í„°ì˜ ì¢…ë¥˜ (ë”•ì…”ë„ˆë¦¬ë¡œ ì…ë ¥)\n",
    "- scoring : ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ì§€í‘œ\n",
    "- cv : cross validationì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ train ë°ì´í„°ì…‹ì„ ë‚˜ëˆ„ëŠ” ì¡°ê°ì˜ ê°œìˆ˜\n",
    "- verbose : ê·¸ë¦¬ë“œ íƒìƒ‰ì„ ì§„í–‰í•˜ë©´ì„œ ì§„í–‰ ê³¼ì •ì„ ì¶œë ¥í•´ì„œ ë³´ì—¬ì¤„ ë©”ì„¸ì§€ì˜ ì–‘ (ìˆ«ìê°€ í´ìˆ˜ë¡ ë” ë§ì€ ë©”ì„¸ì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.)\n",
    "- n_jobs : ê·¸ë¦¬ë“œ íƒìƒ‰ì„ ì§„í–‰í•˜ë©´ì„œ ì‚¬ìš©í•  CPUì˜ ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param ê²½ìš°ì˜ ìˆ˜ : 4 , cross validation ìˆ˜ 5 ë”°ë¼ì„œ ì´ ì‹¤í–‰ ìˆ˜ëŠ” 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íŒŒë¼ë¯¸í„° ì¡°í•©ë§Œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid_model.cv_results_['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ŒìŠ¤íŠ¸ ì ìˆ˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = grid_model.cv_results_['mean_test_score']\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrameìœ¼ë¡œ ë°”ê¾¸ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(params)\n",
    "results['score'] = score\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ê³¼ê°€ ì™œ ìŒìˆ˜ ? scoring ì¸ìì— neg_mean_squared_errorë¥¼ ì…ë ¥í–ˆê¸° ë•Œë¬¸ --> rmseë¡œ ë°”ê¾¸ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ê³¼ì˜ scaleì€ priceì˜ scaleì„ ì¡°ì •í–ˆê¸° ë•Œë¬¸. RMSEê°€ ì•„ë‹Œ RMSLE(log)ë¡œ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.rename(columns={'RMSE': 'RMSLE'})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSLE ë‚®ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.sort_values('RMSLE')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•¨ìˆ˜í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    # GridSearchCV ëª¨ë¸ë¡œ ì´ˆê¸°í™”\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "    \n",
    "    # ëª¨ë¸ fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # ê²°ê³¼ê°’ ì €ì¥\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "    \n",
    "    # ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "    \n",
    "    # RMSLE ê°’ ê³„ì‚° í›„ ì •ë ¬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì œì¶œ ê³¼ì • í•¨ìˆ˜í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)\n",
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ê³¼ë¡œ ì–»ì€ ê°€ì¥ ì¢‹ì€ ì¡°í•©ì„ í†µí•´ í•™ìŠµ í›„ csv íŒŒì¼ë¡œ ë§Œë“¤ì!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth=10, n_estimators=100, random_state=random_state)\n",
    "model.fit(train, y)\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.expm1(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv íŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price ë®ì–´ ì”Œìš°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
    "submission.to_csv(submission_csv_path, index=False)\n",
    "print(submission_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•¨ìˆ˜í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(model, train, y, test, model_name, rmsle=None):\n",
    "    model.fit(train, y)\n",
    "    prediction = model.predict(test)\n",
    "    prediction = np.expm1(prediction)\n",
    "    data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(model, train, y, test, 'lgbm', rmsle='0.0168')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
